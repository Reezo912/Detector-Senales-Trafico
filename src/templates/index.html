<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Proyecto de Detección de Señales</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');
    body{font-family:'Poppins',sans-serif}
  </style>
</head>
<body class="bg-gray-100 text-gray-800">
<!-- NAV -->
<nav class="bg-white shadow-md fixed w-full z-10">
  <div class="container mx-auto px-6 py-4 flex justify-between items-center">
    <h1 class="text-2xl font-semibold text-green-600">Detección de Señales</h1>
    <ul class="flex gap-6">
      <li><a href="#overview" class="hover:text-green-600">Inicio</a></li>
      <li><a href="#demo" class="hover:text-green-600">Demo</a></li>
      <li><a href="#model" class="hover:text-green-600">Modelo</a></li>
      <li><a href="#contact" class="hover:text-green-600">Contacto</a></li>
    </ul>
  </div>
</nav>

<main class="pt-20">
  <!-- HERO -->
  <header id="overview" class="container mx-auto px-6 py-20 text-center">
    <h2 class="text-4xl md:text-5xl font-bold mb-6">Proyecto de Detección de Señales</h2>
    <p class="text-xl text-gray-600 mb-10">Sube un vídeo o imagen y observa la detección en vivo.</p>
    <button id="scrollDemo" class="bg-green-600 text-white px-8 py-3 rounded-lg shadow hover:bg-green-500 transition">Ir a Demo</button>
  </header>

  <!-- DEMO -->
  <section id="demo" class="container mx-auto px-6 py-16">
    <h3 class="text-3xl font-semibold text-center mb-8">Demo</h3>

    <!-- Contenedor de resultado -->
    <div class="flex justify-center">
      <img id="display" src="" alt="Vista" class="w-[1280px] h-[720px] bg-black rounded shadow-md object-contain"/>
    </div>

    <!-- Subida -->
    <div class="mt-10 max-w-xl mx-auto bg-white p-6 rounded-lg shadow space-y-4">
      <input id="fileInput" type="file" accept="image/*,video/*" class="w-full border rounded px-3 py-2"/>
      <p id="status" class="text-sm text-gray-600"></p>

      <div class="flex justify-center gap-4">
        <button id="playBtn" class="bg-green-600 text-white px-6 py-2 rounded shadow">Procesar</button>
        <button id="stopBtn" class="bg-red-600 text-white px-6 py-2 rounded shadow">Parar</button>
      </div>
    </div>
  </section>


  <!-- MODEL DESCRIPTION -->
  <section id="model" class="bg-white py-16">
    <div class="container mx-auto px-6">
      <h3 class="text-3xl font-semibold text-center mb-12">¿Cómo funciona el modelo?</h3>
      <div class="grid md:grid-cols-3 gap-8">
        <!-- Datos -->
        <div class="bg-gray-50 p-6 rounded-lg shadow hover:shadow-lg transition">
          <h4 class="text-xl font-semibold mb-3">Dataset</h4>
          <p class="text-gray-600">2 300 imágenes etiquetadas de señales de tráfico españolas + 800 fotografías propias. Aumento de datos con rotación y condiciones de iluminación.</p>
        </div>
        <!-- Arquitectura -->
        <div class="bg-gray-50 p-6 rounded-lg shadow hover:shadow-lg transition">
          <h4 class="text-xl font-semibold mb-3">Arquitectura</h4>
          <p class="text-gray-600">YOLOv8‑n personalizado (9,6M parámetros) finetuneado 50 épocas sobre el dataset. Inferencia &lt; 25 ms/frame en GPU T4.</p>
        </div>
        <!-- Métricas -->
        <div class="bg-gray-50 p-6 rounded-lg shadow hover:shadow-lg transition">
          <h4 class="text-xl font-semibold mb-3">Resultados</h4>
          <p class="text-gray-600">mAP@0.5 = 92 %, precisión = 90 %, recall = 89 %. Falsos positivos reducidos con NMS en tiempo real.</p>
        </div>
      </div>
      <!-- Pipeline -->
      <div class="mt-12 grid md:grid-cols-2 gap-8 items-center">
        <div class="bg-gray-50 p-6 rounded-lg shadow">
          <h4 class="text-xl font-semibold mb-4">Pipeline en Producción</h4>
          <ul class="list-disc list-inside text-gray-600 space-y-2">
            <li>OpenCV captura cada frame &rarr; redimensiona a 640×640.</li>
            <li>YOLOv8 realiza inferencia; extrae bounding boxes &amp; clase.</li>
            <li>Señales detectadas se sobreponen en el stream (color según confianza).</li>
            <li>FPS y estadísticas se imprimen en overlay.</li>
          </ul>
        </div>
        <div class="text-center">
          <img src="/static/img_example.jpg" alt="Ejemplo de detección" class="rounded shadow mx-auto"/>
        </div>
      </div>
    </div>
  </section>

  <!-- CONTACTO -->
  <footer id="contact" class="bg-gray-800 text-gray-200 py-12 text-center">
    <h4 class="text-2xl font-semibold mb-4">Contacto</h4>
    <p>Escríbeme a <a href="mailto:tu.email@dominio.com" class="text-green-400 hover:underline">tu.email@dominio.com</a></p>
  </footer>
</main>

  <script>
    const disp   = document.getElementById('display');
    const finput = document.getElementById('fileInput');
    const status = document.getElementById('status');
    const play   = document.getElementById('playBtn');
    const stop   = document.getElementById('stopBtn');
    const scroll = document.getElementById('scrollDemo');

    play.onclick = async () => {
      const f = finput.files[0];
      if (!f) { alert('Selecciona un archivo'); return; }
      const fd = new FormData(); fd.append('file', f);
      status.textContent = 'Subiendo…';
      try {
        const r = await fetch('/upload', { method:'POST', body: fd });
        const j = await r.json();
        if (j.file) {
          const url = (f.type.startsWith('video') ? '/video?file=' : '/image?file=') + encodeURIComponent(j.file);
          disp.src = url;
          status.textContent = 'Procesando…';
        } else throw new Error(j.error || 'fallo');
      } catch(e){ status.textContent = 'Error: '+e.message; }
    };

    stop.onclick = () => disp.removeAttribute('src');
    scroll.onclick = () => document.getElementById('demo').scrollIntoView({behavior:'smooth'});
  </script>
</body>
</html>
